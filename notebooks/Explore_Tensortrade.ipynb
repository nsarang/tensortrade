{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install TensorTrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:49.289976Z",
     "start_time": "2020-11-08T20:24:49.283147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not \"cdDone\" in globals():\n",
    "    %cd -q ..\n",
    "    cdDone = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:49.302436Z",
     "start_time": "2020-11-08T20:24:49.292111Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !python3 -m pip install git+https://github.com/nsarang/tensortrade.git --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.200436Z",
     "start_time": "2020-11-08T20:24:49.304189Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from tenacity import retry, retry_if_exception_type, stop_after_attempt\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.526383Z",
     "start_time": "2020-11-08T20:24:50.202196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import ccxt\n",
    "\n",
    "# import ccxt.async_support as ccxt\n",
    "\n",
    "creds = {\n",
    "    \"binance\": {\n",
    "        \"apiKey\": \"jxlzo1mxQ1PDckz4aYgH2WDgFxpJjBu47r3OB4vyLyZkEeyJ4xjOM6m32mvsIgmu\",\n",
    "        \"secret\": \"EffQgaLRPl52q0YEpVKcIHDeqyrFBQWm2K1Er99egbQ1c75X7fDREg4UtzhSaCJM\",\n",
    "    },\n",
    "    \"ftx\": {\n",
    "        \"apiKey\": \"4HO0ffan2qCuTHI06w-Wt-1Bj74WHWYeq4L4-5Ga\",\n",
    "        \"secret\": \"jY85jbW05BWNCkhkathvKfUSl6lGdNgyZXrWnL3W\",\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "exchange = ccxt.binance(\n",
    "    {\n",
    "        **creds[\"binance\"],\n",
    "        \"enableRateLimit\": True,\n",
    "        # 'options': {\n",
    "        #     'defaultType': 'spot', // spot, future, margin\n",
    "        # },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.582342Z",
     "start_time": "2020-11-08T20:24:50.528541Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@retry(retry=retry_if_exception_type(ccxt.NetworkError), stop=stop_after_attempt(3))\n",
    "def get_historical_data(\n",
    "    symbol,\n",
    "    exchange,\n",
    "    timeframe,\n",
    "    start_date=None,\n",
    "    limit=500,\n",
    "    max_per_page=500,\n",
    "    backup_fp=None,\n",
    "):\n",
    "    \"\"\"Get historical OHLCV for a symbol pair\n",
    "\n",
    "    Decorators:\n",
    "        retry\n",
    "\n",
    "    Args:\n",
    "        symbol (str): Contains the symbol pair to operate on i.e. BURST/BTC\n",
    "        exchange (str): Contains the exchange to fetch the historical data from.\n",
    "        timeframe (str): A string specifying the ccxt time unit i.e. 5m or 1d.\n",
    "        start_date (int, optional): Timestamp in milliseconds.\n",
    "        max_periods (int, optional): Defaults to 100. Maximum number of time periods\n",
    "          back to fetch data for.\n",
    "\n",
    "    Returns:\n",
    "        list: Contains a list of lists which contain timestamp, open, high, low, close, volume.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if timeframe not in exchange.timeframes:\n",
    "            raise ValueError(\n",
    "                \"{} does not support {} timeframe for OHLCV data. Possible values are: {}\".format(\n",
    "                    exchange, timeframe, list(exchange.timeframes)\n",
    "                )\n",
    "            )\n",
    "    except AttributeError:\n",
    "        self.logger.error(\n",
    "            \"%s interface does not support timeframe queries! We are unable to fetch data!\",\n",
    "            exchange,\n",
    "        )\n",
    "        raise AttributeError(sys.exc_info())\n",
    "\n",
    "    timeframe_regex = re.compile(\"([0-9]+)([a-zA-Z])\")\n",
    "    timeframe_matches = timeframe_regex.match(timeframe)\n",
    "    time_quantity = timeframe_matches.group(1)\n",
    "    time_period = timeframe_matches.group(2)\n",
    "    timedelta_values = {\n",
    "        \"m\": \"minutes\",\n",
    "        \"h\": \"hours\",\n",
    "        \"d\": \"days\",\n",
    "        \"w\": \"weeks\",\n",
    "        \"M\": \"months\",\n",
    "        \"y\": \"years\",\n",
    "    }\n",
    "\n",
    "    timedelta_args = {timedelta_values[time_period]: int(time_quantity)}\n",
    "    single_frame = timedelta(**timedelta_args)\n",
    "\n",
    "    if not start_date:\n",
    "        start_datetime = datetime.now() - (limit * single_frame)\n",
    "        start_date = int(start_datetime.timestamp() * 1000)\n",
    "\n",
    "    stop_limit = limit or np.inf\n",
    "\n",
    "    try:\n",
    "        historical_data = []\n",
    "        cursor = int(start_date)\n",
    "        while True:\n",
    "            ohlcv = exchange.fetch_ohlcv(\n",
    "                symbol, timeframe=timeframe, since=cursor, limit=limit\n",
    "            )\n",
    "            historical_data += ohlcv\n",
    "            if not ohlcv:\n",
    "                break\n",
    "            if len(historical_data) >= stop_limit:\n",
    "                historical_data = historical_data[:limit]\n",
    "                break\n",
    "            cursor = ohlcv[-1][0] + 1\n",
    "    except:\n",
    "        if historical_data and backup_fp:\n",
    "            convert_to_dataframe(historical_data).to_csv(backup_fp)\n",
    "\n",
    "    if not historical_data:\n",
    "        raise ValueError(\"No historical data provided returned by exchange.\")\n",
    "\n",
    "    #     if len(historical_data) != total:\n",
    "    #         raise ValueError(\"Gaps detected in historical data.\")\n",
    "\n",
    "    # Sort by timestamp in ascending order\n",
    "    historical_data.sort(key=lambda d: d[0])\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.803770Z",
     "start_time": "2020-11-08T20:24:50.583824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestamp_to_datetime(\n",
    "    timestamp, timezone=pytz.timezone(\"America/Montreal\"), to_str=False\n",
    "):\n",
    "    time = datetime.fromtimestamp(timestamp, timezone)\n",
    "    if to_str:\n",
    "        time = time.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
    "    return time\n",
    "\n",
    "\n",
    "def convert_to_dataframe(historical_data):\n",
    "    \"\"\"Converts historical data matrix to a pandas dataframe.\n",
    "\n",
    "    Args:\n",
    "        historical_data (list): A matrix of historical OHCLV data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Contains the historical data in a pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = pd.DataFrame(historical_data)\n",
    "    dataframe.transpose()\n",
    "\n",
    "    #     print(dataframe.head())\n",
    "    dataframe.columns = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    dataframe[\"datetime\"] = dataframe.timestamp.apply(\n",
    "        lambda x: timestamp_to_datetime(x / 1000)\n",
    "    )\n",
    "\n",
    "    dataframe.set_index(\"datetime\", inplace=True, drop=True)\n",
    "    dataframe.drop(\"timestamp\", axis=1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "- .replace(tzinfo=timezone.utc) wont't change the time!\n",
    "- datetime.timestamp() automatically converts to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.843483Z",
     "start_time": "2020-11-08T20:24:50.805229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "since = datetime.strptime(\"2020-10-01\", \"%Y-%m-%d\").timestamp() * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.883365Z",
     "start_time": "2020-11-08T20:24:50.846473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# symbol = \"ETH/USDT\"\n",
    "# filename = symbol.replace(\"/\", \"-\") + \".csv\"\n",
    "\n",
    "# df = convert_to_dataframe(\n",
    "#     get_historical_data(\n",
    "#         symbol,\n",
    "#         exchange,\n",
    "#         timeframe=\"5m\",\n",
    "#         start_date=since,\n",
    "#         limit=100,\n",
    "# #         backup_fp=filename,\n",
    "#     )\n",
    "# )\n",
    "# # df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicator Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.934045Z",
     "start_time": "2020-11-08T20:24:50.885621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift(values: np.ndarray, periods: int, axis, fill_value) -> np.ndarray:\n",
    "    new_values = values\n",
    "\n",
    "    if periods == 0 or values.size == 0:\n",
    "        return new_values.copy()\n",
    "\n",
    "    # make sure array sent to np.roll is c_contiguous\n",
    "    f_ordered = values.flags.f_contiguous\n",
    "    if f_ordered:\n",
    "        new_values = new_values.T\n",
    "        axis = new_values.ndim - axis - 1\n",
    "\n",
    "    if np.prod(new_values.shape):\n",
    "        new_values = np.roll(new_values, periods, axis=axis)\n",
    "\n",
    "    axis_indexer = [slice(None)] * values.ndim\n",
    "    if periods > 0:\n",
    "        axis_indexer[axis] = slice(None, periods)\n",
    "    else:\n",
    "        axis_indexer[axis] = slice(periods, None)\n",
    "    new_values[tuple(axis_indexer)] = fill_value\n",
    "\n",
    "    # restore original order\n",
    "    if f_ordered:\n",
    "        new_values = new_values.T\n",
    "\n",
    "    return new_values\n",
    "\n",
    "\n",
    "def crossing(a, b):\n",
    "    a_plus = shift(a, 1, axis=0, fill_value=0)\n",
    "    b_plus = shift(b, 1, axis=0, fill_value=0)\n",
    "    cross = np.where(\n",
    "        (a <= b) & (a_plus >= b_plus),\n",
    "        1,\n",
    "        np.where(((a >= b) & (a_plus <= b_plus)), -1, 0),\n",
    "    )\n",
    "    return cross\n",
    "\n",
    "\n",
    "def smooth_range(series, period, mult):\n",
    "    wper = period * 2 - 1\n",
    "    diff = (series - series.shift(1, fill_value=0)).abs()\n",
    "    average = ta.EMA(diff, period)\n",
    "    smoothed = ta.EMA(average, wper) * mult\n",
    "    smoothed = pd.Series(smoothed, index=series.index)\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def filter_range(series, smoothrng):\n",
    "    result = series.shift(1, fill_value=0)\n",
    "    for time, (close, smth) in enumerate(zip(series, smoothrng)):\n",
    "        prev = result.iloc[time]\n",
    "        if time == 0 or ((close >= prev - smth) and (close <= prev + smth)):\n",
    "            continue\n",
    "\n",
    "        if close > prev + smth:\n",
    "            prev = close - smth\n",
    "        else:\n",
    "            prev = close + smth\n",
    "        result.iloc[time] = prev\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:50.983982Z",
     "start_time": "2020-11-08T20:24:50.935524Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SWING_CALLS(df):\n",
    "    ema = ta.EMA(df.close, 5)\n",
    "    sma = ta.SMA(df.close, 50)\n",
    "    rsi = ta.RSI(df.close, 14)\n",
    "\n",
    "    color = np.where(\n",
    "        (rsi >= 85) | (rsi <= 15),\n",
    "        \"YELLOW\",\n",
    "        np.where(df.low > sma, \"LIME\", np.where(df.high < sma, \"RED\", \"YELLOW\")),\n",
    "    )\n",
    "\n",
    "    buyexit = rsi > 80\n",
    "    sellexit = rsi < 30\n",
    "\n",
    "    sellcall = (crossing(sma, ema) > 0) & (df.open > df.close)\n",
    "    buycall = (crossing(sma, ema) < 0) & (df.high > sma)\n",
    "\n",
    "    return buyexit, sellexit, sellcall, buycall\n",
    "\n",
    "\n",
    "def Range_Filter_Buy_Sell(df, period=100, range_multiplier=3):\n",
    "    # Smooth Average Range\n",
    "    smoothed = smooth_range(df.close, period, range_multiplier)\n",
    "\n",
    "    # Range Filter\n",
    "    filtered = filter_range(df.close, smoothed)\n",
    "\n",
    "    buycall = (\n",
    "        (df.close > filtered)\n",
    "        & (df.close > df.close.shift(1))\n",
    "        & (filtered > filtered.shift(1))\n",
    "    )\n",
    "    sellcall = (\n",
    "        (df.close < filtered)\n",
    "        & (df.close < df.close.shift(1))\n",
    "        & (filtered < filtered.shift(1))\n",
    "    )\n",
    "    return buycall, sellcall\n",
    "\n",
    "\n",
    "def calculate_profit(ohlvc, buycall, sellcall, start_from=100, trade_fee=0.1):\n",
    "    money = 1\n",
    "    asset = 0\n",
    "    last_buy = ohlvc.iloc[start_from][\"close\"]\n",
    "    trade_cost = 0\n",
    "    trade_fee /= 100\n",
    "    for time, (buy, sell) in enumerate(zip(buycall, sellcall)):\n",
    "        if time < start_from:\n",
    "            continue\n",
    "\n",
    "        if buy and money and (time != len(ohlvc) - 1):\n",
    "            trade_cost += money * trade_fee\n",
    "            money *= 1 - trade_fee\n",
    "            asset = money / ohlvc.iloc[time][\"close\"]\n",
    "            money = 0\n",
    "            last_buy = ohlvc.iloc[time][\"close\"]\n",
    "\n",
    "        elif (sell or (time == len(ohlvc) - 1)) and asset:\n",
    "            money = asset * ohlvc.iloc[time][\"close\"]\n",
    "            trade_cost += money * trade_fee\n",
    "            money *= 1 - trade_fee\n",
    "            asset = 0\n",
    "\n",
    "    return money, trade_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:56.403085Z",
     "start_time": "2020-11-08T20:24:50.985559Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensortrade as tt\n",
    "import tensortrade.env.default as default\n",
    "\n",
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "from tensortrade.feed.core import Stream, DataFeed\n",
    "from tensortrade.oms.exchanges import Exchange, ExchangeOptions\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.instruments import USD, BTC, ETH\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "from tensortrade.agents import DQNAgent, A2CAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:24:57.271342Z",
     "start_time": "2020-11-08T20:24:56.405208Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-17 00:00:00-04:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4280.56</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>2.189061</td>\n",
       "      <td>2017-08-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17 00:05:00-04:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-08-17 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-17 00:10:00-04:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-08-17 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-17 00:15:00-04:00</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4264.88</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>4261.48</td>\n",
       "      <td>0.484666</td>\n",
       "      <td>2017-08-17 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-17 00:20:00-04:00</td>\n",
       "      <td>4264.88</td>\n",
       "      <td>4266.29</td>\n",
       "      <td>4264.88</td>\n",
       "      <td>4266.29</td>\n",
       "      <td>2.328570</td>\n",
       "      <td>2017-08-17 00:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime     open     high      low    close    volume  \\\n",
       "0  2017-08-17 00:00:00-04:00  4261.48  4280.56  4261.48  4261.48  2.189061   \n",
       "1  2017-08-17 00:05:00-04:00  4261.48  4261.48  4261.48  4261.48  0.000000   \n",
       "2  2017-08-17 00:10:00-04:00  4261.48  4261.48  4261.48  4261.48  0.000000   \n",
       "3  2017-08-17 00:15:00-04:00  4261.48  4264.88  4261.48  4261.48  0.484666   \n",
       "4  2017-08-17 00:20:00-04:00  4264.88  4266.29  4264.88  4266.29  2.328570   \n",
       "\n",
       "                 date  \n",
       "0 2017-08-17 00:00:00  \n",
       "1 2017-08-17 00:05:00  \n",
       "2 2017-08-17 00:10:00  \n",
       "3 2017-08-17 00:15:00  \n",
       "4 2017-08-17 00:20:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cdd = CryptoDataDownload()\n",
    "# data = cdd.fetch(\"Coinbase\", \"USD\", \"BTC\", \"1h\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data/BTC-USDT.csv\")\n",
    "date = df[\"datetime\"]\n",
    "date = date.apply(lambda x: x.rsplit(\"-\", 1)[0].split(\".\")[0]) # remove ms and UTC offset (.%f%z)\n",
    "date = pd.to_datetime(date)\n",
    "df[\"date\"] = date\n",
    "df = df.sort_values(\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:09.482366Z",
     "start_time": "2020-11-08T20:24:57.272965Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ta/trend.py:608: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ta/trend.py:612: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ta\n",
    "\n",
    "data = ta.add_all_ta_features(\n",
    "    df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:09.640606Z",
     "start_time": "2020-11-08T20:28:09.484502Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'open', 'high', 'low', 'close', 'volume', 'date',\n",
       "       'volume_adi', 'volume_obv', 'volume_cmf', 'volume_fi', 'momentum_mfi',\n",
       "       'volume_em', 'volume_sma_em', 'volume_vpt', 'volume_nvi', 'volume_vwap',\n",
       "       'volatility_atr', 'volatility_bbm', 'volatility_bbh', 'volatility_bbl',\n",
       "       'volatility_bbw', 'volatility_bbp', 'volatility_bbhi',\n",
       "       'volatility_bbli', 'volatility_kcc', 'volatility_kch', 'volatility_kcl',\n",
       "       'volatility_kcw', 'volatility_kcp', 'volatility_kchi',\n",
       "       'volatility_kcli', 'volatility_dcl', 'volatility_dch', 'trend_macd',\n",
       "       'trend_macd_signal', 'trend_macd_diff', 'trend_sma_fast',\n",
       "       'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow', 'trend_adx',\n",
       "       'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos',\n",
       "       'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix',\n",
       "       'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
       "       'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
       "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
       "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
       "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
       "       'trend_psar_down', 'trend_psar_up_indicator',\n",
       "       'trend_psar_down_indicator', 'momentum_rsi', 'momentum_tsi',\n",
       "       'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n",
       "       'momentum_ao', 'momentum_kama', 'momentum_roc', 'others_dr',\n",
       "       'others_dlr', 'others_cr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features with the feed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:09.774818Z",
     "start_time": "2020-11-08T20:28:09.642071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rsi(price: Stream[float], period: float) -> Stream[float]:\n",
    "    r = price.diff()\n",
    "    upside = r.clamp_min(0).abs()\n",
    "    downside = r.clamp_max(0).abs()\n",
    "    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n",
    "    return 100*(1 - (1 + rs) ** -1)\n",
    "\n",
    "\n",
    "def macd(price: Stream[float], fast: float, slow: float, signal: float) -> Stream[float]:\n",
    "    fm = price.ewm(span=fast, adjust=False).mean()\n",
    "    sm = price.ewm(span=slow, adjust=False).mean()\n",
    "    md = fm - sm\n",
    "    signal = md - md.ewm(span=signal, adjust=False).mean()\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:09.901159Z",
     "start_time": "2020-11-08T20:28:09.776323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = [\n",
    "#     Stream.source(list(data[c]), dtype=\"float\").rename(data[c].name)\n",
    "#     for c in data.columns[2:]\n",
    "# ]\n",
    "\n",
    "# close = Stream.select(features, lambda s: s.name == \"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:10.027447Z",
     "start_time": "2020-11-08T20:28:09.902594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Listener:\n",
    "#     def on_next(self, value):\n",
    "#         print(value)\n",
    "\n",
    "# close.attach(Listener())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:10.152464Z",
     "start_time": "2020-11-08T20:28:10.028967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tensortrade.feed.core import Stream\n",
    "# ss = Stream.source([1, 2, 3, 4, 5], dtype=\"float\")\n",
    "\n",
    "# ff = DataFeed([ss.rolling(2).mean()])\n",
    "# ff.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:10.278334Z",
     "start_time": "2020-11-08T20:28:10.153872Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = [\n",
    "#     close.ewm(span=14).mean().rename(\"ema\"),\n",
    "#     close.ewm(alpha=1).mean().rename(\"sma\"),\n",
    "#     close.log().diff().rename(\"lr\"),\n",
    "#     rsi(close, period=20).rename(\"rsi\"),\n",
    "#     macd(close, fast=10, slow=50, signal=5).rename(\"macd\")\n",
    "# ]\n",
    "\n",
    "# feed = DataFeed(features)\n",
    "# feed.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:10.403485Z",
     "start_time": "2020-11-08T20:28:10.279806Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# for i in range(5):\n",
    "#     obsv = feed.next()\n",
    "#     print(json.dumps(obsv, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:11.226846Z",
     "start_time": "2020-11-08T20:28:10.405053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = data[[x for x in data.columns if not x.startswith(\"date\")]]\n",
    "features = features.pct_change()\n",
    "features = features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:16.350868Z",
     "start_time": "2020-11-08T20:28:11.228473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commission = 0.005\n",
    "window_size = 200\n",
    "\n",
    "feed = DataFeed(\n",
    "    [\n",
    "        Stream.source(list(features[c]), dtype=\"float\").rename(features[c].name)\n",
    "        for c in features.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "renderer_feed = DataFeed(\n",
    "    [\n",
    "        Stream.source(list(data[\"date\"])).rename(\"date\"),\n",
    "        Stream.source(list(data[\"open\"]), dtype=\"float\").rename(\"open\"),\n",
    "        Stream.source(list(data[\"high\"]), dtype=\"float\").rename(\"high\"),\n",
    "        Stream.source(list(data[\"low\"]), dtype=\"float\").rename(\"low\"),\n",
    "        Stream.source(list(data[\"close\"]), dtype=\"float\").rename(\"close\"),\n",
    "        Stream.source(list(data[\"volume\"]), dtype=\"float\").rename(\"volume\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "exchange_opts = ExchangeOptions(commission=commission)\n",
    "coinbase = Exchange(\"coinbase\", service=execute_order, options=exchange_opts)(\n",
    "    Stream.source(list(data[\"close\"]), dtype=\"float\").rename(\"USD/BTC\")\n",
    ")\n",
    "\n",
    "cash = Wallet(coinbase, 10000 * USD)\n",
    "asset = Wallet(coinbase, 0 * BTC)\n",
    "portfolio = Portfolio(USD, [cash, asset])\n",
    "\n",
    "\n",
    "reward_scheme = default.rewards.SimpleProfit()\n",
    "action_scheme = default.actions.SimpleOrders()\n",
    "\n",
    "\n",
    "env = default.create(\n",
    "    feed=feed,\n",
    "    renderer_feed=renderer_feed,\n",
    "    renderer=default.renderers.PlotlyTradingChart(display=False, save_format=\"html\"),\n",
    "    portfolio=portfolio,\n",
    "    action_scheme=action_scheme,\n",
    "    reward_scheme=reward_scheme,\n",
    "    window_size=window_size,\n",
    "    min_periods=window_size,\n",
    "    #         max_allowed_loss=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:07.125352Z",
     "start_time": "2020-11-08T20:36:06.962635Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # for i in range(1000):\n",
    "# #     env.observer.observe(env)\n",
    " \n",
    "# env.observer.observe(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:07.612274Z",
     "start_time": "2020-11-08T20:36:07.428732Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tensortrade.agents import VPGAgent\n",
    "# import tensortrade.agents.vpg.core as vcore\n",
    "\n",
    "# env_fn = lambda: env\n",
    "# agent = VPGAgent(\n",
    "#     env_fn,\n",
    "#     exp_name=\"test\",\n",
    "#     actor_critic=vcore.CNNActorCritic,\n",
    "#     ac_kwargs=dict(device=\"cuda:0\"),\n",
    "#     steps_per_epoch=250,\n",
    "#     train_v_iters=50,\n",
    "#     epochs=1000\n",
    "# )\n",
    "# agent.train(render_interval=3, save_path=\"agents/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:08.705184Z",
     "start_time": "2020-11-08T20:36:08.524469Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import tensortrade.env.default as default\n",
    "from tensortrade.feed.core import DataFeed, Stream\n",
    "from tensortrade.oms.instruments import Instrument\n",
    "from tensortrade.oms.exchanges import Exchange, ExchangeOptions\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "\n",
    "\n",
    "def create_env(config):\n",
    "    features = config[\"features\"].copy()\n",
    "    data = config[\"data\"].copy()\n",
    "    feed = DataFeed(\n",
    "        [\n",
    "            Stream.source(list(features[c]), dtype=\"float\").rename(features[c].name)\n",
    "            for c in features.columns\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    renderer_feed = DataFeed(\n",
    "        [\n",
    "            Stream.source(list(data[\"date\"])).rename(\"date\"),\n",
    "            Stream.source(list(data[\"open\"]), dtype=\"float\").rename(\"open\"),\n",
    "            Stream.source(list(data[\"high\"]), dtype=\"float\").rename(\"high\"),\n",
    "            Stream.source(list(data[\"low\"]), dtype=\"float\").rename(\"low\"),\n",
    "            Stream.source(list(data[\"close\"]), dtype=\"float\").rename(\"close\"),\n",
    "            Stream.source(list(data[\"volume\"]), dtype=\"float\").rename(\"volume\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    exchange_opts = ExchangeOptions(commission=config[\"commission\"])\n",
    "    coinbase = Exchange(\"coinbase\", service=execute_order, options=exchange_opts)(\n",
    "        Stream.source(list(data[\"close\"]), dtype=\"float\").rename(\"USD/BTC\")\n",
    "    )\n",
    "\n",
    "    cash = Wallet(coinbase, 10000 * USD)\n",
    "    asset = Wallet(coinbase, 0 * BTC)\n",
    "    portfolio = Portfolio(USD, [cash, asset])\n",
    "\n",
    "    reward_scheme = default.rewards.SimpleProfit(window_size=config[\"window_size\"])\n",
    "    action_scheme = default.actions.SimpleOrders()\n",
    "\n",
    "    env = default.create(\n",
    "        feed=feed,\n",
    "        #         renderer_feed=renderer_feed,\n",
    "        #         renderer=default.renderers.PlotlyTradingChart(display=False, save_format=\"html\"),\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        window_size=config[\"window_size\"],\n",
    "        min_periods=config[\"window_size\"],\n",
    "        #         max_allowed_loss=0.5,\n",
    "    )\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:09.263378Z",
     "start_time": "2020-11-08T20:36:09.112499Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_norm = data.copy()\n",
    "\n",
    "# z_score = lambda x: (x - x.mean()) / x.std(ddof=0)\n",
    "# abs_max = lambda x: x / x.abs().quantile(0.9)\n",
    "# data_norm[data_norm.columns[2:]] = data_norm[data_norm.columns[2:]].apply(abs_max)\n",
    "# data_norm = data_norm.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:09.631378Z",
     "start_time": "2020-11-08T20:36:09.476011Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"data\": data,\n",
    "    \"features\": features,\n",
    "    \"commission\": 0.005,\n",
    "    \"window_size\": 50,\n",
    "}\n",
    "# environment = create_env(env_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:10.168741Z",
     "start_time": "2020-11-08T20:36:10.000357Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from stable_baselines.common.policies import MlpLnLstmPolicy\n",
    "# from stable_baselines import PPO2\n",
    "\n",
    "# policy = MlpLnLstmPolicy\n",
    "# # params = { \"learning_rate\": 1e-5 }\n",
    "\n",
    "# agent = PPO2(policy, environment, nminibatches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:36:12.591396Z",
     "start_time": "2020-11-08T20:36:12.433453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agent.learn(total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:42:57.019450Z",
     "start_time": "2020-11-08T20:42:56.829350Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-238c091ddf9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mregister_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TradingEnv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, redis_address, redis_port, num_cpus, num_gpus, memory, object_store_memory, resources, driver_object_store_memory, redis_max_memory, log_to_driver, node_ip_address, object_ref_seed, local_mode, redirect_worker_output, redirect_output, ignore_reinit_error, num_redis_shards, redis_max_clients, redis_password, plasma_directory, huge_pages, include_java, include_dashboard, dashboard_host, dashboard_port, job_id, configure_logging, logging_level, logging_format, plasma_store_socket_name, raylet_socket_name, temp_dir, load_code_from_local, java_worker_options, use_pickle, _internal_config, lru_evict, enable_object_reconstruction)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             raise RuntimeError(\"Maybe you called ray.init twice by accident? \"\n\u001b[0m\u001b[1;32m    671\u001b[0m                                \u001b[0;34m\"This error can be suppressed by passing in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                                \u001b[0;34m\"'ignore_reinit_error=True' or by calling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "register_env(\"TradingEnv\", create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:44:07.813923Z",
     "start_time": "2020-11-08T20:44:07.642802Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'sample_batch_size': -1,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'num_gpus': 0,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': True,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action_reward': False,\n",
       "  'state_shape': None,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'custom_options': -1},\n",
       " 'optimizer': {},\n",
       " 'gamma': 0.99,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env_config': {},\n",
       " 'env': None,\n",
       " 'normalize_actions': False,\n",
       " 'clip_rewards': None,\n",
       " 'clip_actions': True,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'lr': 5e-05,\n",
       " 'monitor': False,\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'tf',\n",
       " 'eager_tracing': False,\n",
       " 'no_eager_on_workers': False,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_num_episodes': 10,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'sample_async': False,\n",
       " '_use_trajectory_view_api': False,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'collect_metrics_timeout': 180,\n",
       " 'metrics_smoothing_episodes': 100,\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'min_iter_time_s': 0,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'seed': None,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'memory': 0,\n",
       " 'object_store_memory': 0,\n",
       " 'memory_per_worker': 0,\n",
       " 'object_store_memory_per_worker': 0,\n",
       " 'input': 'sampler',\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent'},\n",
       " 'replay_sequence_length': 1,\n",
       " 'use_pytorch': -1,\n",
       " 'eager': -1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_share_layers': False,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'simple_optimizer': False,\n",
       " '_fake_gpus': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.ppo.DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:47:54.008618Z",
     "start_time": "2020-11-08T20:47:39.982851Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=22738)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=22721)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=22693)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/utils/torch_ops.py:149: UserWarning:\n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=22758)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "from ray.rllib import agents\n",
    "\n",
    "config = agents.ppo.DEFAULT_CONFIG.copy()\n",
    "config.update(\n",
    "    {\n",
    "        \"env\": \"TradingEnv\",\n",
    "        \"env_config\": env_config,\n",
    "        \"log_level\": \"WARN\",\n",
    "        \"framework\": \"torch\",\n",
    "        #         \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"num_gpus\": 2,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = agents.ppo.PPOTrainer(config=config, env=\"TradingEnv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:49:23.689391Z",
     "start_time": "2020-11-08T20:48:50.883177Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_reward_max': -0.03425316733032879,\n",
       " 'episode_reward_min': -32.364811487707875,\n",
       " 'episode_reward_mean': -0.13789486113065083,\n",
       " 'episode_len_mean': 2.0470829068577276,\n",
       " 'episodes_this_iter': 1954,\n",
       " 'policy_reward_min': {},\n",
       " 'policy_reward_max': {},\n",
       " 'policy_reward_mean': {},\n",
       " 'custom_metrics': {},\n",
       " 'hist_stats': {'episode_reward': [-32.19168565248159,\n",
       "   -0.048791587473961284,\n",
       "   -0.14637476242188385,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -0.048791587473961284,\n",
       "   -32.364811487707875,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   -0.03425316733032879,\n",
       "   ...],\n",
       "  'episode_lengths': [501,\n",
       "   1,\n",
       "   3,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   498,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   ...]},\n",
       " 'sampler_perf': {'mean_env_wait_ms': 2.0507896957257894,\n",
       "  'mean_processing_ms': 0.744969180372815,\n",
       "  'mean_inference_ms': 1.8019972355470337},\n",
       " 'off_policy_estimator': {},\n",
       " 'num_healthy_workers': 4,\n",
       " 'timesteps_total': 4000,\n",
       " 'timers': {'sample_time_ms': 7454.568,\n",
       "  'sample_throughput': 536.584,\n",
       "  'learn_time_ms': 18761.956,\n",
       "  'learn_throughput': 213.197,\n",
       "  'update_time_ms': 11.661},\n",
       " 'info': {'learner': {'default_policy': {'allreduce_latency': 0.0,\n",
       "    'cur_kl_coeff': 0.2,\n",
       "    'cur_lr': 5e-05,\n",
       "    'total_loss': 0.8446181993931532,\n",
       "    'policy_loss': -0.20539888890925795,\n",
       "    'vf_loss': 1.0460975114256144,\n",
       "    'vf_explained_var': 0.7521581,\n",
       "    'kl': 0.01959785516373813,\n",
       "    'entropy': 3.02493579685688,\n",
       "    'entropy_coeff': 0.0}},\n",
       "  'num_steps_sampled': 4000,\n",
       "  'num_steps_trained': 4000},\n",
       " 'done': False,\n",
       " 'episodes_total': 1954,\n",
       " 'training_iteration': 1,\n",
       " 'experiment_id': '1bf13af5ca4c49c8bb7b1ee975ad8a7c',\n",
       " 'date': '2020-11-08_15-49-17',\n",
       " 'timestamp': 1604868557,\n",
       " 'time_this_iter_s': 26.27272129058838,\n",
       " 'time_total_s': 26.27272129058838,\n",
       " 'pid': 22143,\n",
       " 'hostname': 'gra899',\n",
       " 'node_ip': '10.29.85.73',\n",
       " 'config': {'num_workers': 4,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'rollout_fragment_length': 200,\n",
       "  'sample_batch_size': -1,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'num_gpus': 2,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'fcnet_hiddens': [256, 256],\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': True,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action_reward': False,\n",
       "   'state_shape': None,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'custom_options': -1},\n",
       "  'optimizer': {},\n",
       "  'gamma': 0.99,\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env_config': {'data':                          datetime      open      high       low     close  \\\n",
       "   0       2017-08-17 00:00:00-04:00   4261.48   4280.56   4261.48   4261.48   \n",
       "   1       2017-08-17 00:05:00-04:00   4261.48   4261.48   4261.48   4261.48   \n",
       "   2       2017-08-17 00:10:00-04:00   4261.48   4261.48   4261.48   4261.48   \n",
       "   3       2017-08-17 00:15:00-04:00   4261.48   4264.88   4261.48   4261.48   \n",
       "   4       2017-08-17 00:20:00-04:00   4264.88   4266.29   4264.88   4266.29   \n",
       "   ...                           ...       ...       ...       ...       ...   \n",
       "   325055  2020-09-23 14:15:00-04:00  10463.54  10463.55  10424.24  10425.14   \n",
       "   325056  2020-09-23 14:20:00-04:00  10425.15  10447.18  10424.98  10431.49   \n",
       "   325057  2020-09-23 14:25:00-04:00  10431.49  10443.66  10430.12  10438.93   \n",
       "   325058  2020-09-23 14:30:00-04:00  10438.77  10442.95  10432.12  10438.69   \n",
       "   325059  2020-09-23 14:35:00-04:00  10438.69  10442.03  10433.74  10433.98   \n",
       "   \n",
       "               volume                date    volume_adi     volume_obv  \\\n",
       "   0         2.189061 2017-08-17 00:00:00 -2.189061e+00       2.189061   \n",
       "   1         0.000000 2017-08-17 00:05:00 -2.189061e+00       2.189061   \n",
       "   2         0.000000 2017-08-17 00:10:00 -2.189061e+00       2.189061   \n",
       "   3         0.484666 2017-08-17 00:15:00 -2.673727e+00       2.673727   \n",
       "   4         2.328570 2017-08-17 00:20:00 -3.451570e-01       5.002297   \n",
       "   ...            ...                 ...           ...            ...   \n",
       "   325055  392.211358 2020-09-23 14:15:00  1.115122e+06 -733413.930473   \n",
       "   325056  183.343822 2020-09-23 14:20:00  1.115046e+06 -733230.586651   \n",
       "   325057  136.154376 2020-09-23 14:25:00  1.115087e+06 -733094.432275   \n",
       "   325058  160.029950 2020-09-23 14:30:00  1.115122e+06 -733254.462225   \n",
       "   325059   55.036381 2020-09-23 14:35:00  1.115070e+06 -733309.498606   \n",
       "   \n",
       "           volume_cmf  ...  momentum_uo  momentum_stoch  momentum_stoch_signal  \\\n",
       "   0              NaN  ...          NaN             NaN                    NaN   \n",
       "   1              NaN  ...          NaN             NaN                    NaN   \n",
       "   2              NaN  ...          NaN             NaN                    NaN   \n",
       "   3              NaN  ...          NaN             NaN                    NaN   \n",
       "   4              NaN  ...          NaN             NaN                    NaN   \n",
       "   ...            ...  ...          ...             ...                    ...   \n",
       "   325055   -0.256659  ...    32.461770        1.374256              15.001383   \n",
       "   325056   -0.324950  ...    31.353086       11.070392              16.769806   \n",
       "   325057   -0.271411  ...    35.323483       22.430905              11.625185   \n",
       "   325058   -0.232565  ...    37.547901       22.064437              18.521912   \n",
       "   325059   -0.287092  ...    34.536940       14.872500              19.789281   \n",
       "   \n",
       "           momentum_wr  momentum_ao  momentum_kama  momentum_roc  others_dr  \\\n",
       "   0               NaN          NaN            NaN           NaN -45.776931   \n",
       "   1               NaN          NaN            NaN           NaN   0.000000   \n",
       "   2               NaN          NaN            NaN           NaN   0.000000   \n",
       "   3               NaN          NaN            NaN           NaN   0.000000   \n",
       "   4               NaN          NaN            NaN           NaN   0.112872   \n",
       "   ...             ...          ...            ...           ...        ...   \n",
       "   325055   -98.625744   -14.585529            NaN     -0.511132  -0.366989   \n",
       "   325056   -88.929608   -18.452412            NaN     -0.467725   0.060910   \n",
       "   325057   -77.569095   -20.840500            NaN     -0.370975   0.071323   \n",
       "   325058   -77.935563   -23.329382            NaN     -0.413945  -0.002299   \n",
       "   325059   -85.127500   -26.245206            NaN     -0.442067  -0.045121   \n",
       "   \n",
       "           others_dlr   others_cr  \n",
       "   0              NaN    0.000000  \n",
       "   1         0.000000    0.000000  \n",
       "   2         0.000000    0.000000  \n",
       "   3         0.000000    0.000000  \n",
       "   4         0.112808    0.112872  \n",
       "   ...            ...         ...  \n",
       "   325055   -0.367664  144.636605  \n",
       "   325056    0.060892  144.785614  \n",
       "   325057    0.071297  144.960202  \n",
       "   325058   -0.002299  144.954570  \n",
       "   325059   -0.045131  144.844045  \n",
       "   \n",
       "   [325060 rows x 79 columns],\n",
       "   'features':             open      high       low     close    volume  volume_adi  \\\n",
       "   0       0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "   1       0.000000 -0.004457  0.000000  0.000000 -1.000000    0.000000   \n",
       "   2       0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "   3       0.000000  0.000798  0.000000  0.000000  0.000000    0.221404   \n",
       "   4       0.000798  0.000331  0.000798  0.001129  3.804484   -0.870908   \n",
       "   ...          ...       ...       ...       ...       ...         ...   \n",
       "   325055  0.001295 -0.000014 -0.002307 -0.003670  2.651546   -0.000336   \n",
       "   325056 -0.003669 -0.001564  0.000071  0.000609 -0.532538   -0.000068   \n",
       "   325057  0.000608 -0.000337  0.000493  0.000713 -0.257382    0.000037   \n",
       "   325058  0.000698 -0.000068  0.000192 -0.000023  0.175357    0.000031   \n",
       "   325059 -0.000008 -0.000088  0.000155 -0.000451 -0.656087   -0.000046   \n",
       "   \n",
       "           volume_obv  volume_cmf  volume_fi  momentum_mfi  ...  momentum_uo  \\\n",
       "   0         0.000000    0.000000   0.000000      0.000000  ...     0.000000   \n",
       "   1         0.000000    0.000000   0.000000      0.000000  ...     0.000000   \n",
       "   2         0.000000    0.000000   0.000000      0.000000  ...     0.000000   \n",
       "   3         0.221404    0.000000   0.000000      0.000000  ...     0.000000   \n",
       "   4         0.870908    0.000000   0.000000      0.000000  ...     0.000000   \n",
       "   ...            ...         ...        ...           ...  ...          ...   \n",
       "   325055    0.000535    2.162742  27.493529     -0.289250  ...    -0.210945   \n",
       "   325056   -0.000250    0.266074  -0.217833     -0.030556  ...    -0.034154   \n",
       "   325057   -0.000186   -0.164759  -0.226262      0.047831  ...     0.126635   \n",
       "   325058    0.000218   -0.143125  -0.138770      0.290680  ...     0.062973   \n",
       "   325059    0.000075    0.234455  -0.110828     -0.117474  ...    -0.080190   \n",
       "   \n",
       "           momentum_stoch  momentum_stoch_signal  momentum_wr  momentum_ao  \\\n",
       "   0             0.000000               0.000000     0.000000     0.000000   \n",
       "   1             0.000000               0.000000     0.000000     0.000000   \n",
       "   2             0.000000               0.000000     0.000000     0.000000   \n",
       "   3             0.000000               0.000000     0.000000     0.000000   \n",
       "   4             0.000000               0.000000     0.000000     0.000000   \n",
       "   ...                ...                    ...          ...          ...   \n",
       "   325055       -0.963706              -0.230769     0.587276     0.394971   \n",
       "   325056        7.055556               0.117884    -0.098312     0.265118   \n",
       "   325057        1.026207              -0.306779    -0.127747     0.129419   \n",
       "   325058       -0.016338               0.593257     0.004724     0.119425   \n",
       "   325059       -0.325952               0.068425     0.092281     0.124985   \n",
       "   \n",
       "           momentum_kama  momentum_roc  others_dr  others_dlr  others_cr  \n",
       "   0                 0.0      0.000000   0.000000    0.000000   0.000000  \n",
       "   1                 0.0      0.000000  -1.000000    0.000000   0.000000  \n",
       "   2                 0.0      0.000000   0.000000    0.000000   0.000000  \n",
       "   3                 0.0      0.000000   0.000000    0.000000   0.000000  \n",
       "   4                 0.0      0.000000   0.000000    0.000000   0.000000  \n",
       "   ...               ...           ...        ...         ...        ...  \n",
       "   325055            0.0      3.256503  -3.834468   -3.841519  -0.006191  \n",
       "   325056            0.0     -0.084923  -1.165974   -1.165619   0.001030  \n",
       "   325057            0.0     -0.206853   0.170940    0.170879   0.001206  \n",
       "   325058            0.0      0.115829  -1.032235   -1.032247  -0.000039  \n",
       "   325059            0.0      0.067938  18.625451   18.629654  -0.000762  \n",
       "   \n",
       "   [325060 rows x 77 columns],\n",
       "   'commission': 0.005,\n",
       "   'window_size': 50},\n",
       "  'env': 'TradingEnv',\n",
       "  'normalize_actions': False,\n",
       "  'clip_rewards': None,\n",
       "  'clip_actions': True,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'lr': 5e-05,\n",
       "  'monitor': False,\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'no_eager_on_workers': False,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_num_episodes': 10,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'sample_async': False,\n",
       "  '_use_trajectory_view_api': False,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'collect_metrics_timeout': 180,\n",
       "  'metrics_smoothing_episodes': 100,\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'min_iter_time_s': 0,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'seed': None,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'memory': 0,\n",
       "  'object_store_memory': 0,\n",
       "  'memory_per_worker': 0,\n",
       "  'object_store_memory_per_worker': 0,\n",
       "  'input': 'sampler',\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {},\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent'},\n",
       "  'replay_sequence_length': 1,\n",
       "  'use_pytorch': -1,\n",
       "  'eager': -1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 30,\n",
       "  'lr_schedule': None,\n",
       "  'vf_share_layers': False,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'simple_optimizer': True,\n",
       "  '_fake_gpus': False},\n",
       " 'time_since_restore': 26.27272129058838,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 1,\n",
       " 'perf': {'cpu_util_percent': 9.688775510204081,\n",
       "  'ram_util_percent': 28.475510204081633,\n",
       "  'gpu_util_percent0': 0.0,\n",
       "  'vram_util_percent0': 0.9449909821282177,\n",
       "  'gpu_util_percent1': 0.0,\n",
       "  'vram_util_percent1': 0.03025086079685195}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:28:17.717802Z",
     "start_time": "2020-11-08T20:28:17.590693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "# # Postprocess the perturbed config to ensure it's still valid\n",
    "# def explore(config):\n",
    "#     # ensure we collect enough timesteps to do sgd\n",
    "#     if config[\"train_batch_size\"] < config[\"sgd_minibatch_size\"] * 2:\n",
    "#         config[\"train_batch_size\"] = config[\"sgd_minibatch_size\"] * 2\n",
    "#     # ensure we run at least one sgd iter\n",
    "#     if config[\"num_sgd_iter\"] < 1:\n",
    "#         config[\"num_sgd_iter\"] = 1\n",
    "#     return config\n",
    "\n",
    "\n",
    "# pbt = PopulationBasedTraining(\n",
    "#     time_attr=\"time_total_s\",\n",
    "#     metric=\"episode_reward_mean\",\n",
    "#     mode=\"max\",\n",
    "#     perturbation_interval=100,\n",
    "#     resample_probability=0.25,\n",
    "#     # Specifies the mutations of these hyperparams\n",
    "#     hyperparam_mutations={\n",
    "#         \"lambda\": lambda: random.uniform(0.9, 1.0),\n",
    "#         \"clip_param\": lambda: random.uniform(0.01, 0.5),\n",
    "#         \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
    "#         \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
    "#         \"sgd_minibatch_size\": lambda: random.randint(32, 4096),\n",
    "#         \"train_batch_size\": lambda: random.randint(2000, 16000),\n",
    "#     },\n",
    "#     custom_explore_fn=explore,\n",
    "# )\n",
    "\n",
    "# tune.run(\n",
    "#     \"PPO\",\n",
    "#     checkpoint_freq=10,\n",
    "#     name=\"show_me_the_money_test\",\n",
    "#     #     scheduler=pbt,\n",
    "#     #     num_samples=8,\n",
    "#     config={\n",
    "#         \"env\": \"TradingEnv\",\n",
    "#         \"env_config\": env_config,\n",
    "#         \"framework\": \"tf\",\n",
    "# #         \"log_level\": \"DEBUG\",\n",
    "#         \"kl_coeff\": 1.0,\n",
    "# #         \"num_workers\": 8,\n",
    "#         \"num_gpus\": 1,\n",
    "#         #         \"model\": {\n",
    "#         #             \"free_log_std\": True\n",
    "#         #         },\n",
    "#         # These params are tuned from a fixed starting value.\n",
    "#         \"lambda\": 0.95,\n",
    "#         \"clip_param\": 0.2,\n",
    "#         \"lr\": 1e-4,\n",
    "#         # These params start off randomly drawn from a set.\n",
    "#         \"num_sgd_iter\": tune.sample_from(lambda spec: random.choice([10, 20, 30])),\n",
    "#         \"sgd_minibatch_size\": tune.sample_from(\n",
    "#             lambda spec: random.choice([32, 128, 512, 2048])\n",
    "#         ),\n",
    "#         \"train_batch_size\": tune.sample_from(\n",
    "#             lambda spec: random.choice([1000, 2000, 4000])\n",
    "#         ),\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T20:34:14.392129Z",
     "start_time": "2020-11-08T20:28:17.719218Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:28:17,850\tINFO resource_spec.py:231 -- Starting Ray with 75.93 GiB memory available for workers and up to 36.54 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-11-08 15:28:19,216\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m 2020-11-08 15:28:42,387\tINFO trainer.py:605 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m 2020-11-08 15:28:42,387\tINFO trainer.py:632 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m 2020-11-08 15:28:57,677\tINFO trainable.py:251 -- Trainable.setup took 18.324 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:871: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22736)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:871: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22798)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:871: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22803)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:871: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22697)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m WARNING:tensorflow:From /project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/rllib/policy/tf_policy.py:871: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22696)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-29-21\n",
      "  done: false\n",
      "  episode_len_mean: 2.0253164556962027\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.12648918699068065\n",
      "  episode_reward_min: -32.29843022738116\n",
      "  episodes_this_iter: 1975\n",
      "  episodes_total: 1975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 3.0136678218841553\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.030988000333309174\n",
      "        model: {}\n",
      "        policy_loss: -0.24930539727210999\n",
      "        total_loss: 0.26197585463523865\n",
      "        vf_explained_var: 0.8822211027145386\n",
      "        vf_loss: 0.5050836205482483\n",
      "    num_steps_sampled: 4000\n",
      "    num_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 11.916129032258064\n",
      "    gpu_util_percent0: 0.09806451612903226\n",
      "    gpu_util_percent1: 0.10903225806451612\n",
      "    ram_util_percent: 19.41935483870967\n",
      "    vram_util_percent0: 0.03375222802257378\n",
      "    vram_util_percent1: 0.04640369388953242\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 2.102559720543237\n",
      "    mean_inference_ms: 1.41675469696821\n",
      "    mean_processing_ms: 0.7391843089194616\n",
      "  time_since_restore: 23.771937608718872\n",
      "  time_this_iter_s: 23.771937608718872\n",
      "  time_total_s: 23.771937608718872\n",
      "  timers:\n",
      "    learn_throughput: 689.3\n",
      "    learn_time_ms: 5802.987\n",
      "    load_throughput: 16914.954\n",
      "    load_time_ms: 236.477\n",
      "    sample_throughput: 226.951\n",
      "    sample_time_ms: 17624.919\n",
      "    update_time_ms: 4.207\n",
      "  timestamp: 1604867361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:29:26,446\tWARNING util.py:137 -- The `process_trial` operation took 4.794903993606567 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.5/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         23.7719</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">-0.126489</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-29-40\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 5975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.9884085655212402\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.025158191099762917\n",
      "        model: {}\n",
      "        policy_loss: -0.23904326558113098\n",
      "        total_loss: -0.2096727043390274\n",
      "        vf_explained_var: -1.0\n",
      "        vf_loss: 0.021823106333613396\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.958333333333334\n",
      "    gpu_util_percent0: 0.10666666666666667\n",
      "    gpu_util_percent1: 0.12375000000000001\n",
      "    ram_util_percent: 21.40416666666667\n",
      "    vram_util_percent0: 0.04369568781767503\n",
      "    vram_util_percent1: 0.05418921134612231\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 2.3797792771171173\n",
      "    mean_inference_ms: 1.4105273865867052\n",
      "    mean_processing_ms: 1.0185482381642434\n",
      "  time_since_restore: 38.15647745132446\n",
      "  time_this_iter_s: 14.38453984260559\n",
      "  time_total_s: 38.15647745132446\n",
      "  timers:\n",
      "    learn_throughput: 724.024\n",
      "    learn_time_ms: 5524.675\n",
      "    load_throughput: 25502.831\n",
      "    load_time_ms: 156.845\n",
      "    sample_throughput: 303.388\n",
      "    sample_time_ms: 13184.453\n",
      "    update_time_ms: 4.555\n",
      "  timestamp: 1604867380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:29:45,460\tWARNING util.py:137 -- The `process_trial` operation took 4.436284303665161 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.1/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         38.1565</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-30-01\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 9975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.44999998807907104\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.965888261795044\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02458980865776539\n",
      "        model: {}\n",
      "        policy_loss: -0.22442153096199036\n",
      "        total_loss: -0.2077280730009079\n",
      "        vf_explained_var: -1.0\n",
      "        vf_loss: 0.005628045182675123\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.93478260869565\n",
      "    gpu_util_percent0: 0.1117391304347826\n",
      "    gpu_util_percent1: 0.12304347826086957\n",
      "    ram_util_percent: 21.878260869565214\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 2.675218806192105\n",
      "    mean_inference_ms: 1.4202055117560404\n",
      "    mean_processing_ms: 1.112562304772921\n",
      "  time_since_restore: 54.56993794441223\n",
      "  time_this_iter_s: 16.41346049308777\n",
      "  time_total_s: 54.56993794441223\n",
      "  timers:\n",
      "    learn_throughput: 736.011\n",
      "    learn_time_ms: 5434.703\n",
      "    load_throughput: 30549.557\n",
      "    load_time_ms: 130.935\n",
      "    sample_throughput: 323.465\n",
      "    sample_time_ms: 12366.09\n",
      "    update_time_ms: 4.548\n",
      "  timestamp: 1604867401\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:30:06,343\tWARNING util.py:137 -- The `process_trial` operation took 4.288194179534912 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.3/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         54.5699</td><td style=\"text-align: right;\">12000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-30-24\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 13975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 0.675000011920929\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.9495604038238525\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021628987044095993\n",
      "        model: {}\n",
      "        policy_loss: -0.20630142092704773\n",
      "        total_loss: -0.1902754008769989\n",
      "        vf_explained_var: -1.0\n",
      "        vf_loss: 0.0014264353085309267\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.328000000000001\n",
      "    gpu_util_percent0: 0.12\n",
      "    gpu_util_percent1: 0.1304\n",
      "    ram_util_percent: 21.948\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.05418921134612232\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.0146951199888856\n",
      "    mean_inference_ms: 1.422367582199604\n",
      "    mean_processing_ms: 1.2323582538870743\n",
      "  time_since_restore: 73.01758193969727\n",
      "  time_this_iter_s: 18.447643995285034\n",
      "  time_total_s: 73.01758193969727\n",
      "  timers:\n",
      "    learn_throughput: 740.934\n",
      "    learn_time_ms: 5398.589\n",
      "    load_throughput: 34114.663\n",
      "    load_time_ms: 117.252\n",
      "    sample_throughput: 321.17\n",
      "    sample_time_ms: 12454.45\n",
      "    update_time_ms: 4.547\n",
      "  timestamp: 1604867424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:30:29,652\tWARNING util.py:137 -- The `process_trial` operation took 4.735310792922974 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.4/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         73.0176</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-30-50\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 17975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.0125000476837158\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.93463134765625\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02068272791802883\n",
      "        model: {}\n",
      "        policy_loss: -0.2127881795167923\n",
      "        total_loss: -0.1911633312702179\n",
      "        vf_explained_var: -0.9764094948768616\n",
      "        vf_loss: 0.0006836322136223316\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 8.939285714285715\n",
      "    gpu_util_percent0: 0.10428571428571429\n",
      "    gpu_util_percent1: 0.11821428571428572\n",
      "    ram_util_percent: 22.032142857142862\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.253264609300429\n",
      "    mean_inference_ms: 1.525111685655422\n",
      "    mean_processing_ms: 1.2436879322400596\n",
      "  time_since_restore: 94.32403469085693\n",
      "  time_this_iter_s: 21.306452751159668\n",
      "  time_total_s: 94.32403469085693\n",
      "  timers:\n",
      "    learn_throughput: 739.032\n",
      "    learn_time_ms: 5412.482\n",
      "    load_throughput: 32435.122\n",
      "    load_time_ms: 123.323\n",
      "    sample_throughput: 306.915\n",
      "    sample_time_ms: 13032.944\n",
      "    update_time_ms: 4.549\n",
      "  timestamp: 1604867450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:30:55,621\tWARNING util.py:137 -- The `process_trial` operation took 4.475148677825928 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 27.9/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">          94.324</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-31-17\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 21975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.9247846603393555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01923118531703949\n",
      "        model: {}\n",
      "        policy_loss: -0.24136170744895935\n",
      "        total_loss: -0.2118106186389923\n",
      "        vf_explained_var: -0.485330194234848\n",
      "        vf_loss: 0.0003437565464992076\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.200000000000001\n",
      "    gpu_util_percent0: 0.08964285714285714\n",
      "    gpu_util_percent1: 0.10071428571428571\n",
      "    ram_util_percent: 22.407142857142855\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.498411708981806\n",
      "    mean_inference_ms: 1.5132526937394797\n",
      "    mean_processing_ms: 1.252326065849173\n",
      "  time_since_restore: 115.83909296989441\n",
      "  time_this_iter_s: 21.515058279037476\n",
      "  time_total_s: 115.83909296989441\n",
      "  timers:\n",
      "    learn_throughput: 742.358\n",
      "    learn_time_ms: 5388.239\n",
      "    load_throughput: 34596.918\n",
      "    load_time_ms: 115.617\n",
      "    sample_throughput: 296.745\n",
      "    sample_time_ms: 13479.565\n",
      "    update_time_ms: 4.497\n",
      "  timestamp: 1604867477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:31:21,635\tWARNING util.py:137 -- The `process_trial` operation took 4.388918399810791 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         115.839</td><td style=\"text-align: right;\">24000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-31-44\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 25975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.917729139328003\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01885765977203846\n",
      "        model: {}\n",
      "        policy_loss: -0.22041568160057068\n",
      "        total_loss: -0.19156573712825775\n",
      "        vf_explained_var: 0.05072556436061859\n",
      "        vf_loss: 0.0002098778641084209\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.549999999999999\n",
      "    gpu_util_percent0: 0.09142857142857143\n",
      "    gpu_util_percent1: 0.09571428571428571\n",
      "    ram_util_percent: 22.492857142857144\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.7373305473850724\n",
      "    mean_inference_ms: 1.50745225078701\n",
      "    mean_processing_ms: 1.2588171920781812\n",
      "  time_since_restore: 138.59761428833008\n",
      "  time_this_iter_s: 22.75852131843567\n",
      "  time_total_s: 138.59761428833008\n",
      "  timers:\n",
      "    learn_throughput: 744.138\n",
      "    learn_time_ms: 5375.351\n",
      "    load_throughput: 36253.785\n",
      "    load_time_ms: 110.333\n",
      "    sample_throughput: 286.394\n",
      "    sample_time_ms: 13966.765\n",
      "    update_time_ms: 4.469\n",
      "  timestamp: 1604867504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:31:49,102\tWARNING util.py:137 -- The `process_trial` operation took 4.602098703384399 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.1/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         138.598</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-32-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 29975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.906156063079834\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.019808780401945114\n",
      "        model: {}\n",
      "        policy_loss: -0.22781768441200256\n",
      "        total_loss: -0.19754701852798462\n",
      "        vf_explained_var: 0.1633036881685257\n",
      "        vf_loss: 0.00018606946105137467\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.233333333333333\n",
      "    gpu_util_percent0: 0.085\n",
      "    gpu_util_percent1: 0.08866666666666667\n",
      "    ram_util_percent: 22.56666666666667\n",
      "    vram_util_percent0: 0.04369568781767504\n",
      "    vram_util_percent1: 0.05418921134612233\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 3.9933164139685524\n",
      "    mean_inference_ms: 1.505227681026356\n",
      "    mean_processing_ms: 1.284881817253064\n",
      "  time_since_restore: 163.85865426063538\n",
      "  time_this_iter_s: 25.261039972305298\n",
      "  time_total_s: 163.85865426063538\n",
      "  timers:\n",
      "    learn_throughput: 745.453\n",
      "    learn_time_ms: 5365.865\n",
      "    load_throughput: 37594.065\n",
      "    load_time_ms: 106.4\n",
      "    sample_throughput: 273.305\n",
      "    sample_time_ms: 14635.658\n",
      "    update_time_ms: 4.517\n",
      "  timestamp: 1604867534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:32:18,800\tWARNING util.py:137 -- The `process_trial` operation took 4.31837797164917 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.2/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         163.859</td><td style=\"text-align: right;\">32000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-32-43\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 33975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 1.5187499523162842\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.8905768394470215\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.02421150915324688\n",
      "        model: {}\n",
      "        policy_loss: -0.2346608191728592\n",
      "        total_loss: -0.19768841564655304\n",
      "        vf_explained_var: 0.09161016345024109\n",
      "        vf_loss: 0.00020118649990763515\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.428571428571427\n",
      "    gpu_util_percent0: 0.08892857142857144\n",
      "    gpu_util_percent1: 0.10035714285714285\n",
      "    ram_util_percent: 22.635714285714293\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.200575438066002\n",
      "    mean_inference_ms: 1.5026113878633034\n",
      "    mean_processing_ms: 1.2892900394235844\n",
      "  time_since_restore: 188.7783465385437\n",
      "  time_this_iter_s: 24.919692277908325\n",
      "  time_total_s: 188.7783465385437\n",
      "  timers:\n",
      "    learn_throughput: 746.472\n",
      "    learn_time_ms: 5358.543\n",
      "    load_throughput: 38812.729\n",
      "    load_time_ms: 103.059\n",
      "    sample_throughput: 264.652\n",
      "    sample_time_ms: 15114.184\n",
      "    update_time_ms: 4.501\n",
      "  timestamp: 1604867563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:32:48,572\tWARNING util.py:137 -- The `process_trial` operation took 4.740934610366821 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.3/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         188.778</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-33-14\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 37975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 2.278125047683716\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.887251138687134\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.021725798025727272\n",
      "        model: {}\n",
      "        policy_loss: -0.21904334425926208\n",
      "        total_loss: -0.16936667263507843\n",
      "        vf_explained_var: 0.1778380423784256\n",
      "        vf_loss: 0.0001826071529649198\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.77857142857143\n",
      "    gpu_util_percent0: 0.09357142857142856\n",
      "    gpu_util_percent1: 0.09285714285714286\n",
      "    ram_util_percent: 22.664285714285718\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.415218770033169\n",
      "    mean_inference_ms: 1.5029649998638441\n",
      "    mean_processing_ms: 1.2947722752443993\n",
      "  time_since_restore: 214.54938197135925\n",
      "  time_this_iter_s: 25.77103543281555\n",
      "  time_total_s: 214.54938197135925\n",
      "  timers:\n",
      "    learn_throughput: 747.344\n",
      "    learn_time_ms: 5352.287\n",
      "    load_throughput: 39806.345\n",
      "    load_time_ms: 100.486\n",
      "    sample_throughput: 256.824\n",
      "    sample_time_ms: 15574.858\n",
      "    update_time_ms: 4.485\n",
      "  timestamp: 1604867594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:33:18,941\tWARNING util.py:137 -- The `process_trial` operation took 4.481310844421387 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.3/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         214.549</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_f2954_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-11-08_15-33-45\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: -0.044111006657483354\n",
      "  episode_reward_mean: -0.06165849903349898\n",
      "  episode_reward_min: -0.0787172587220103\n",
      "  episodes_this_iter: 4000\n",
      "  episodes_total: 41975\n",
      "  experiment_id: ca850159fb35464ea22b7a512bd2a74c\n",
      "  experiment_tag: '0'\n",
      "  hostname: gra899\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        cur_kl_coeff: 3.417187452316284\n",
      "        cur_lr: 9.999999747378752e-05\n",
      "        entropy: 2.881641149520874\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01824815385043621\n",
      "        model: {}\n",
      "        policy_loss: -0.18896375596523285\n",
      "        total_loss: -0.12642009556293488\n",
      "        vf_explained_var: 0.15114478766918182\n",
      "        vf_loss: 0.0001862721110228449\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 10.29.85.73\n",
      "  num_healthy_workers: 4\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 9.39285714285714\n",
      "    gpu_util_percent0: 0.09464285714285713\n",
      "    gpu_util_percent1: 0.09821428571428571\n",
      "    ram_util_percent: 22.71785714285715\n",
      "    vram_util_percent0: 0.043695687817675036\n",
      "    vram_util_percent1: 0.054189211346122326\n",
      "  pid: 22736\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 4.625900779330896\n",
      "    mean_inference_ms: 1.5032860747511498\n",
      "    mean_processing_ms: 1.2993099537559796\n",
      "  time_since_restore: 241.21864414215088\n",
      "  time_this_iter_s: 26.669262170791626\n",
      "  time_total_s: 241.21864414215088\n",
      "  timers:\n",
      "    learn_throughput: 754.438\n",
      "    learn_time_ms: 5301.957\n",
      "    load_throughput: 47217.494\n",
      "    load_time_ms: 84.714\n",
      "    sample_throughput: 251.966\n",
      "    sample_time_ms: 15875.188\n",
      "    update_time_ms: 4.52\n",
      "  timestamp: 1604867625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: f2954_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08 15:33:50,060\tWARNING util.py:137 -- The `process_trial` operation took 4.332521915435791 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.4/125.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/32 CPUs, 2/2 GPUs, 0.0/75.93 GiB heap, 0.0/25.2 GiB objects (0/1.0 GPUType:P100)<br>Result logdir: /home/nimas/ray_results/PPO<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">    reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_f2954_00000</td><td>RUNNING </td><td>10.29.85.73:22736</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         241.219</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">-0.0616585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a835dddd9237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mreuse_actors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mcheckpoint_at_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mglobal_checkpoint_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m )\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/6007383/nimas/env-python3.6/lib/python3.6/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1670\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m         )\n\u001b[1;32m   1674\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\"episode_reward_mean\": 100},\n",
    "    config={\n",
    "        \"env\": \"TradingEnv\",\n",
    "        \"env_config\": env_config,\n",
    "        \"log_level\": \"WARN\",\n",
    "        \"framework\": \"tf\",\n",
    "#         \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 4,\n",
    "        \"num_gpus\": 2,\n",
    "#         \"clip_rewards\": True,\n",
    "        \"lr\": 1e-4,\n",
    "#         \"lr_schedule\": [\n",
    "# #             [0, 1e-1],\n",
    "# #             [int(1e2), 1e-2],\n",
    "# #             [int(1e3), 1e-3],\n",
    "#             [int(1e4), 1e-4],\n",
    "#             [int(1e5), 1e-5],\n",
    "#             [int(1e6), 1e-6],\n",
    "#             [int(1e7), 1e-7],\n",
    "#         ],\n",
    "#         \"gamma\": 0,\n",
    "#         \"observation_filter\": \"MeanStdFilter\",\n",
    "#         \"lambda\": 0.72,\n",
    "#         \"vf_loss_coeff\": 0.5,\n",
    "#         \"entropy_coeff\": 0.01,\n",
    "    },\n",
    "#     local_dir=\"./ray\",\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 1},\n",
    "    reuse_actors=True,\n",
    "    checkpoint_at_end=True,\n",
    "    global_checkpoint_period=np.inf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
